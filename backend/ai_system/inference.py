#!/usr/bin/env python3
"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ
"""

import os
import sys
import json
import torch
import numpy as np
from typing import List, Dict, Any
import logging

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from neural_network import MedicalDiagnosisNetwork, MedicalDataProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MedicalDiagnosisInference:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
    
    def __init__(self, models_dir: str = "trained_models"):
        self.models_dir = models_dir
        self.model = None
        self.data_processor = MedicalDataProcessor()
        self.is_loaded = False
        
        # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
        self.model_path = os.path.join(models_dir, 'best_medical_model.pth')
        self.processor_path = os.path.join(models_dir, 'data_processor.json')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        self.load_model()
    
    def load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            if not os.path.exists(self.model_path) or not os.path.exists(self.processor_path):
                logger.warning(f"–§–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {self.models_dir}")
                return False
            
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–∞–Ω–Ω—ã—Ö
            with open(self.processor_path, 'r', encoding='utf-8') as f:
                processor_data = json.load(f)
            
            self.data_processor.symptom_vocab = processor_data['symptom_vocab']
            self.data_processor.disease_vocab = processor_data['disease_vocab']
            self.data_processor.vocab_size = processor_data['vocab_size']
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∫–µ–π–ª–µ—Ä
            self.data_processor.scaler.mean_ = np.array(processor_data['scaler_mean'])
            self.data_processor.scaler.scale_ = np.array(processor_data['scaler_scale'])
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            checkpoint = torch.load(self.model_path, map_location='cpu')
            self.model = MedicalDiagnosisNetwork(
                input_size=checkpoint['input_size'],
                hidden_sizes=checkpoint['hidden_sizes'],
                output_size=checkpoint['output_size']
            )
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            self.is_loaded = True
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            logger.info(f"   - –°–∏–º–ø—Ç–æ–º–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ: {len(self.data_processor.symptom_vocab)}")
            logger.info(f"   - –ó–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –≤ —Å–ª–æ–≤–∞—Ä–µ: {len(self.data_processor.disease_vocab)}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def predict(self, symptoms: List[str], top_k: int = 3) -> Dict[str, Any]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è –ø–æ —Å–∏–º–ø—Ç–æ–º–∞–º"""
        if not self.is_loaded:
            return {
                'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å.',
                'predictions': []
            }
        
        try:
            # –û—á–∏—â–∞–µ–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–∏–º–ø—Ç–æ–º—ã
            cleaned_symptoms = self._clean_symptoms(symptoms)
            
            if not cleaned_symptoms:
                return {
                    'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–∏–º–ø—Ç–æ–º—ã',
                    'predictions': []
                }
            
            # –ö–æ–¥–∏—Ä—É–µ–º —Å–∏–º–ø—Ç–æ–º—ã
            symptom_vector = self.data_processor.encode_symptoms(cleaned_symptoms)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Å–∏–º–ø—Ç–æ–º–∞–º–∏
            recognized_symptoms = []
            for symptom in cleaned_symptoms:
                if symptom in self.data_processor.symptom_vocab:
                    recognized_symptoms.append(symptom)
                else:
                    # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                    for vocab_symptom in self.data_processor.symptom_vocab.keys():
                        if symptom.lower() in vocab_symptom.lower() or vocab_symptom.lower() in symptom.lower():
                            recognized_symptoms.append(vocab_symptom)
                            break
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä
            symptom_vector = self.data_processor.scaler.transform([symptom_vector])
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                input_tensor = torch.FloatTensor(symptom_vector)
                output, confidence = self.model(input_tensor)
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-k –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                probabilities = torch.softmax(output, dim=1)
                top_probs, top_indices = torch.topk(probabilities, k=min(top_k, output.size(1)))
                
                predictions = []
                for i in range(top_probs.size(1)):
                    disease_idx = top_indices[0][i].item()
                    probability = top_probs[0][i].item()
                    confidence_score = confidence[0][0].item()
                    
                    disease_name = self.data_processor.decode_disease(disease_idx)
                    
                    predictions.append({
                        'disease': disease_name,
                        'probability': round(probability * 100, 2),
                        'confidence': round(confidence_score * 100, 2)
                    })
                
                return {
                    'predictions': predictions,
                    'input_symptoms': symptoms,
                    'recognized_symptoms': recognized_symptoms,
                    'processing_time': 0.01,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
                    'model_status': 'active'
                }
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
            return {
                'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ: {str(e)}',
                'predictions': []
            }
    
    def _clean_symptoms(self, symptoms: List[str]) -> List[str]:
        """–û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–º–ø—Ç–æ–º–æ–≤"""
        cleaned = []
        
        for symptom in symptoms:
            if isinstance(symptom, str):
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
                cleaned_symptom = symptom.strip().lower()
                
                # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                import re
                cleaned_symptom = re.sub(r'[^\w\s]', '', cleaned_symptom)
                
                if cleaned_symptom and len(cleaned_symptom) > 2:
                    cleaned.append(cleaned_symptom)
        
        return cleaned
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        if not self.is_loaded:
            return {'error': '–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}
        
        try:
            history_path = os.path.join(self.models_dir, 'training_history.json')
            
            info = {
                'model_loaded': self.is_loaded,
                'symptoms_count': len(self.data_processor.symptom_vocab),
                'diseases_count': len(self.data_processor.disease_vocab),
                'model_path': self.model_path,
                'processor_path': self.processor_path
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å
            if os.path.exists(history_path):
                with open(history_path, 'r', encoding='utf-8') as f:
                    history = json.load(f)
                    
                    info['architecture'] = history.get('model_architecture', {})
                    
                    # –õ—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    if 'val_accuracies' in history and history['val_accuracies']:
                        info['best_accuracy'] = max(history['val_accuracies'])
                    
                    if 'train_accuracies' in history and history['train_accuracies']:
                        info['final_train_accuracy'] = history['train_accuracies'][-1]
            
            return info
            
        except Exception as e:
            return {'error': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {str(e)}'}
    
    def get_symptoms_list(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤"""
        if not self.is_loaded:
            return []
        
        return sorted(list(self.data_processor.symptom_vocab.keys()))
    
    def get_diseases_list(self) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π"""
        if not self.is_loaded:
            return []
        
        return sorted(list(self.data_processor.disease_vocab.keys()))
    
    def find_similar_symptoms(self, symptom: str, limit: int = 5) -> List[str]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤"""
        if not self.is_loaded:
            return []
        
        symptom = symptom.lower().strip()
        similar = []
        
        for vocab_symptom in self.data_processor.symptom_vocab.keys():
            if symptom in vocab_symptom.lower() or vocab_symptom.lower() in symptom:
                similar.append(vocab_symptom)
        
        return similar[:limit]

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API
medical_ai = MedicalDiagnosisInference()

def diagnose_symptoms(symptoms: List[str], top_k: int = 3) -> Dict[str, Any]:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Å–∏–º–ø—Ç–æ–º–æ–≤ (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ API)"""
    return medical_ai.predict(symptoms, top_k)

def get_model_status() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏"""
    return medical_ai.get_model_info()

def get_available_symptoms() -> List[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∏–º–ø—Ç–æ–º–æ–≤"""
    return medical_ai.get_symptoms_list()

def get_available_diseases() -> List[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π"""
    return medical_ai.get_diseases_list()

def search_symptoms(query: str, limit: int = 5) -> List[str]:
    """–ü–æ–∏—Å–∫ —Å–∏–º–ø—Ç–æ–º–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
    return medical_ai.find_similar_symptoms(query, limit)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üß† –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è AI –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞")
    print("=" * 40)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏
    status = get_model_status()
    if 'error' in status:
        print(f"‚ùå {status['error']}")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–∞–Ω–¥–æ–π:")
        print("   python train_model.py --epochs 50")
        return
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞:")
    print(f"   - –°–∏–º–ø—Ç–æ–º–æ–≤: {status['symptoms_count']}")
    print(f"   - –ó–∞–±–æ–ª–µ–≤–∞–Ω–∏–π: {status['diseases_count']}")
    if 'best_accuracy' in status:
        print(f"   - –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {status['best_accuracy']:.2f}%")
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    print("\nü©∫ –í–≤–µ–¥–∏—Ç–µ —Å–∏–º–ø—Ç–æ–º—ã (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é) –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞:")
    
    while True:
        try:
            user_input = input("\n> ").strip()
            
            if user_input.lower() in ['exit', 'quit', '–≤—ã—Ö–æ–¥']:
                print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                break
            
            if not user_input:
                continue
            
            # –†–∞–∑–¥–µ–ª—è–µ–º —Å–∏–º–ø—Ç–æ–º—ã
            symptoms = [s.strip() for s in user_input.split(',')]
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ–º
            result = diagnose_symptoms(symptoms)
            
            if 'error' in result:
                print(f"‚ùå {result['error']}")
            else:
                print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:")
                print(f"   –í–≤–µ–¥–µ–Ω–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã: {', '.join(symptoms)}")
                if result['recognized_symptoms']:
                    print(f"   –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã: {', '.join(result['recognized_symptoms'])}")
                
                print(f"\nüéØ –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è:")
                for i, pred in enumerate(result['predictions'], 1):
                    print(f"   {i}. {pred['disease']}: {pred['probability']:.1f}% (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {pred['confidence']:.1f}%)")
        
        except KeyboardInterrupt:
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main() 